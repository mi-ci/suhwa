<h1 align="center"><img src="https://raw.githubusercontent.com/ABSphreak/ABSphreak/master/gifs/Hi.gif" width="30px"> 프로젝트 헬로수화</h1>
<p align="center">
  <a href="https://github.com/Ratheshan03/readme-typing-svg"><img src="https://readme-typing-svg.herokuapp.com?lines=배은영;임유나;도규림;임태창;장우진;변우성;&center=true&width=700&height=70"></a>
  <img src="https://i.imgur.com/9WG7R5G.jpeg">
  <img src="https://i.imgur.com/xjeaL4Q.jpeg">
</p>


<!-- About Section -->
 # About Us
 
<p>
 <img align="right" width="350" src="/assets/programmer.gif" alt="Coding gif" />
  
 ✌️ &emsp;  MBC아카데미에서 만났습니다 <br/><br/>
 ❤️ &emsp; 인공지능을 사랑하는 5인입니다<br/><br/>
 📧 &emsp; 언제든 연락주세요: stormeight@naver.com<br/><br/>
 💬 &emsp; 무엇이든 물어보세요 [here](https://github.com/mi-ci/project-HB/issues)

</p>

<br/>
<br/>

## 언어

![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
<br/>
<br/>

## 라이브러리

![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white)
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white)
![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white)
![Static Badge](https://img.shields.io/badge/-mediapipe-blue)
<br/>
<br/>
## 프레임워크

![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white)
<br/>
<br/>

## ETC

![Static Badge](https://img.shields.io/badge/-Rpi4-red)

<br/>














1. 본 프로젝트 연구의 필요성 및 목적

   의사소통은 인간이 사회생활을 하기 위해서 가장 필수적으로 가지고 있어야 하는 능력으로 사람의 의사나 감정의 소통으로‘가지고 있는 생각이나 뜻이 서로 통함’이라는 의미를 지니고 있다. 상호간 소통을 위해서 사용되는 비언어적 요소들까지 포함이 된다. 하지만 농인들은 말하지 못하고 듣지 못하는 점이 의사소통에 있어서 걸림돌이 되기 때문에 많은 시간과 노력을 들여가며 수화를 배워 타인과 소통하려고 노력한다.

   장애인들과 비장애인들의 의사소통 문제를 해결하기 위하여 수화에 관한 연구가 진행되어 왔다. 하지만 대부분 동작보다는 지문자와 지숫자 등 수형인식에 관한 연구이거나 비수지적 요소(신체, 팔, 표정 등)를 고려하지 않은 연구였고 외국의 사례가 많았다. 그마저도 상용화한 사례들은 드물었다. 그리고 상용화에 성공한 사례들은 장치를 이용한 고가의 웨어러블 센서 또는 깊이 카메라를 통한 의사소통 방법이었다.

   이로 인하여 본 논문에서는 기존의 수형인식에서 나아가 수화 동작을 인식하고자 하였고 비싼 고가의 웨어러블 센서나 깊이 카메라를 구매하지 않아도 높고 정확한 동작을 인식하여 기존 의사소통의 문제를 해결하고자 한다.

3. 프로젝트 적용 대상 및 장소

- 프로젝트 적용 장소: (농인이 운영하는) 카페 사업장
- 프로젝트 적용 대상: 청각장애인 바리스타

4. 프로젝트 도입 효과

   경제활동에 활발히 참여하게 되는 시기인 30~54세의 장애인은  2022년도 기준 515,921명으로 전체 인구의 19.4%에 달하는 것으로 확인되었다. 그가운데 취업자 수는 2023년 5월 기준 277,947명으로 확인되어 53.0%의 고용률을 보이고 있다.
   이처럼 장애인들의 점진적인 증가 추세와 이들의 활발한 사회 참여 현상은 장애인이 우리사회의 사회적 존재로서의 명확한 지위를 가지며 사회에 통합되어 살아갈 당위성을 인식하게 한다. 이를 이루기 위해서는 경제적 자립은 매우 중요한 요소라 할 수 있다.
   본 프로젝트를 통하여 청각장애인들이 일반인들과의 의사소통에서의 겪는 어려움을 극복하게 도움을 주기 위한 수화인식 프로그램을 개발하여 이들의 언어 장벽을 극복하게 하고 나아가 청각장애인들의 사회진출에 도움을 주는 효과를 위하여 기획되었다!


<h1 align="center">
  헬로수화
</h1>

헬로 수화는 아이들이 재밌게 수화를 배울 수 있도록 만든 웹 애플리케이션입니다.
<br>
최대 2명이서 라즈베리파이 카메라를 사용하여 수화 퀴즈를 풀 수 있습니다.
<br>
<br>
<a href="https://58a2-1-233-65-186.ngrok-free.app">헬로수화</a>에서 체험 해보실 수 있습니다.


<h2 align="center">
  헬로수화 (수화 교육용 앱)
</h2>

<table align="center" border="0">
  <tr>
    <td>
- 프로젝트 적용 장소: (농인이 운영하는) 카페 사업장
- 프로젝트 적용 대상: 청각장애인 바리스타
    </td>
    <td align="center" width="400px">
      <img align="center" src="https://user-images.githubusercontent.com/69165598/123177212-b16f0700-d439-11eb-8a21-8b414273f1e1.gif"/>
    </td>
  </tr>
</table>

<br>








<h2 align="center">
  Command Books
</h2>

<p align="center">
  <img src="https://user-images.githubusercontent.com/69165598/123372905-502e5d00-d539-11eb-81c2-46b8bbf929cc.gif" width="100%"/>
  <br>
  <sub>
    The above video shows Auto Maple consistently performing a mechanically advanced ability combination.
  </sub>
</p>
  
<table align="center" border="0">
  <tr>
    <td width="100%">
경제활동에 활발히 참여하게 되는 시기인 30~54세의 장애인은  2022년도 기준 515,921명으로 전체 인구의 19.4%에 달하는 것으로 확인되었다. 그가운데 취업자 수는 2023년 5월 기준 277,947명으로 확인되어 53.0%의 고용률을 보이고 있다.
   이처럼 장애인들의 점진적인 증가 추세와 이들의 활발한 사회 참여 현상은 장애인이 우리사회의 사회적 존재로서의 명확한 지위를 가지며 사회에 통합되어 살아갈 당위성을 인식하게 한다. 이를 이루기 위해서는 경제적 자립은 매우 중요한 요소라 할 수 있다.
   본 프로젝트를 통하여 청각장애인들이 일반인들과의 의사소통에서의 겪는 어려움을 극복하게 도움을 주기 위한 수화인식 프로그램을 개발하여 이들의 언어 장벽을 극복하게 하고 나아가 청각장애인들의 사회진출에 도움을 주는 효과를 위하여 기획되었다!
    </td>
  </tr>
</table>
  
<br>







<h2 align="center">
  Routines
</h2>

<table align="center" border="0">
  <tr>
    <td width="350px">
      <p align="center">
        <img src="https://user-images.githubusercontent.com/69165598/150469699-d8a94ab4-7d70-49c3-8736-a9018996f39a.png"/>
        <br>
        <sub>
          Click <a href="https://github.com/tanjeffreyz02/auto-maple/blob/f13d87c98e9344e0a4fa5c6f85ffb7e66860afc0/routines/dcup2.csv">here</a> to view the entire routine.
        </sub>
      </p>
    </td>
    <td>
A routine is a user-created CSV file that tells Auto Maple where to move and what commands to use at each location. A custom compiler within Auto Maple parses through the selected routine and converts it into a list of <code>Component</code> objects that can then be executed by the program. An error message is printed for every line that contains invalid parameters, and those lines are ignored during the conversion. 
<br><br>
Below is a summary of the most commonly used routine components:
<ul>
  <li>
    <b><code>Point</code></b> stores the commands directly below it and will execute them in that order once the character is within <code>move_tolerance</code> of the specified location. There are also a couple optional keyword arguments:
    <ul>
      <li>
        <code>adjust</code> fine-tunes the character's position to be within <code>adjust_tolerance</code> of the target location before executing any commands.
      </li>
      <li>
        <code>frequency</code> tells the Point how often to execute. If set to N, this Point will execute once every N iterations.
      </li>
      <li>
        <code>skip</code> tells the Point whether to run on the first iteration or not. If set to True and frequency is N, this Point will execute on the N-1th iteration.
      </li>
    </ul>
  </li>
  <li>
    <b><code>Label</code></b> acts as a reference point that can help organize the routine into sections as well as create loops.
  </li>
  <li>
    <b><code>Jump</code></b> jumps to the given label from anywhere in the routine.
  </li>
  <li>
    <b><code>Setting</code></b> updates the specified setting to the given value. It can be placed anywhere in the routine, so different parts of the same routine can have different settings. All editable settings can be found at the bottom of <a href="https://github.com/tanjeffreyz02/auto-maple/blob/v2/settings.py">settings.py</a>.
  </li>
</ul>
    </td>
  </tr>
</table>

<br>








<h2 align="center">
  Runes
</h2>

<p align="center">
  <img src="https://user-images.githubusercontent.com/69165598/123479558-f61fad00-d5b5-11eb-914c-8f002a96dd62.gif" width="100%"/>
</p>

<table align="center" border="0">
  <tr>
    <td width="100%">
Auto Maple has the ability to automatically solve "runes", or in-game arrow key puzzles. It first uses OpenCV's color filtration and <b>Canny edge detection</b> algorithms to isolate the arrow keys and reduce as much background noise as possible. Then, it runs multiple inferences on the preprocessed frames using a custom-trained <b>TensorFlow</b> model until two inferences agree. Because of this preprocessing, Auto Maple is extremely accurate at solving runes in all kinds of (often colorful and chaotic) environments.
    </td>
  </tr>
</table>


<br>









<h2 align="center">
  Video Demonstration
</h2>

<p align="center">
  <a href="https://www.youtube.com/watch?v=qs8Nw55edhg"><b>Click below to watch the full video</b></a>
</p>

<p align="center">
  <a href="https://www.youtube.com/watch?v=qs8Nw55edhg">
    <img src="https://user-images.githubusercontent.com/69165598/123308656-c5b61100-d4d8-11eb-99ac-c465665474b5.gif" width="600px"/>
  </a>
</p>

<br>



<h2 align="center">
  Setup
</h2>

<ol>
  <li>
    Download and install <a href="https://www.python.org/downloads/">Python3</a>.
  </li>
  <li>
    Download and install the latest version of <a href="https://developer.nvidia.com/cuda-downloads">CUDA Toolkit</a>.
  </li>
  <li>
    Download and install <a href="https://git-scm.com/download/win">Git</a>.
  </li>
  <li>
    Download and unzip the latest <a href="https://github.com/tanjeffreyz02/auto-maple/releases">Auto Maple release</a>.
  </li>
  <li>
    Download the <a href="https://drive.google.com/drive/folders/1SPdTNF4KZczoWyWTgfyTBRvLvy7WSGpu?usp=sharing">TensorFlow model</a> and unzip the "models" folder into Auto Maple's "assets" directory.
  </li>
  <li>
    Inside Auto Maple's main directory, open a command prompt and run:
    <pre><code>python -m pip install -r requirements.txt</code></pre>
  </li>
  <li>
    Lastly, create a desktop shortcut by running:
    <pre><code>python setup.py</code></pre>
    This shortcut uses absolute paths, so feel free to move it wherever you want. However, if you move Auto Maple's main directory, you will need to run <code>python setup.py</code> again to generate a new shortcut. To keep the command prompt open after Auto Maple closes, run the above command with the <code>--stay</code> flag.
  </li>
</ol>
